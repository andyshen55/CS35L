I set up the lab environment with the following shell commands:
locale
export LC_ALL='C'
sort /usr/share/dict/words > words
wget https://web.cs.ucla.edu/classes/fall19/cs35L/assign/assign2.html



I then ran the prescribed shell commands.

cat assign2.html | tr -c 'A-Za-z' '[\n*]': This command outputs the HTML file
with all non-alphabetical characters replaced with newlines.

cat assign2.html | tr -cs 'A-Za-z' '[\n*]': The output of this command differed
from the previous one in that it squeezed all consecutive newlines into a
single newline. This made the output vastly more readable.

cat assign2.html | tr -cs 'A-Za-z' '[\n*]' | sort: The output of this command
was the alphabetically sorted version of the previous command.

cat assign2.html | tr -cs 'A-Za-z' '[\n*]' | sort -u: The output of this command
was the same as the previous command, except with non-unique instances of words
removed.

cat assign2.html | tr -cs 'A-Za-z' '[\n*]' | sort -u | comm - words: The
output of this command compares the sorted output of the previous command
(sorted-assign) against the alphabetically sorted list of words in words. It
splits the output into three columns:
the first displays lines unique to sorted-assign, the second displays lines
unique to words, and the third displays lines found in both.

cat assign2.html | tr -cs 'A-Za-z' '[\n*]' | sort -u | comm -23 - words: The
output of this command is the same as that of the previous command, except
with columns 2 and 3 not being displayed. In other words, this command displays
all the lines that are unique to sorted-assign.



After running the shell commands, I had to extract a list of Hawaiian words
from the given website. I ran the command:
wget -O hawaiian.html https://www.mauimapp.com/moolelo/hwnwdshw.htm
to get a local copy of the HTML file from the prescribed website.

In order to automate the systematic ruleset prescribed in the assignment
specification, I wrote a shell script buildwords

In pseudocode, buildwords matches all lines with enclosing <td> tags, as
all the Hawaiian words are contained within these tags. It then removes all
'?', '<ul>', '</ul>' occurences as prescribed by the spec. I then removed the
enclosing <td> tags and replaced grave accents with apostrophes. buildwords.sh
then separates phrases into individual words and filters out any words that
contain letters that aren't present in the Hawaiian alphabet. The remaining
words are then sorted alphabetically and pruend for repeat occurences.

emacs buildwords



#! /bin/bash
#Builds Hawaiian dictionary by parsing input HTML file

#Matches lines enclosed in <td> tags
grep -E "<td>.*</td>" $@ |

#Removes tags and ? char
sed 's/\?//g' |
sed 's/<u>//g' |
sed 's/<\/u>//g' | 
sed 's/<td>//g' |
sed "s/<\/td>//g" |

#Replaces ASCII grave accents with apostrophes
sed "s/\`/\'/g" |

#separates phrases into individual words (on separate lines)
tr ',' '\n' |
tr ' ' '\n' |

#truncates extraneous newlines
tr -s '\n' |

#converts to lowercase
tr [:upper:] [:lower:] |

#deletes lines containing non-Hawaiian alphabetical characters
sed "/[^pk\'mnwlhaeiou]/d" |

#filters unique words alphabetically
sort -u



After writing the shell script, I ran the command:
./buildwords < hawaiian.html | less > hwords

With my newly created Hawaiian dictionary, I ran a HAWAIIANCHECKER command on
assign2.html (which I had previously downloaded with wget). The output of the
following command was the number of misspelled words: 492.
tr [:upper:] [:lower:] < assign2.html | tr -cs "A-Za-z\'" '[\n*]' |
sort -u | comm -23 - hwords | wc -w

I then ran the same command on hwords, with the expected output being 0. (As
there shouldn't be any difference between the two input files in terms of valid
words) The following command output 0:
tr [:upper:] [:lower:] < hwords | tr -cs "A-Za-z\'" '[\n*]' | sort -u |
comm -23 - hwords | wc -w

I then ran the given ENGLISHCHECKER on assign2.html. The output of the following
command (the number of misspelled English words) was 83:
cat assign2.html | tr -cs 'A-Za-z' '[\n*]' | sort -u | comm -23 - words | wc -w



Examples of words that are misspelled as English but not Hawaiian:
wiki
okina

Examples of words that are misspelled as Hawaiian but not English:
when
main